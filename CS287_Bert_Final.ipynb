{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS287_Bert_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexisjihyeross/cs287_causality_project/blob/master/CS287_Bert_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6q18d8QUDlc9",
        "colab_type": "code",
        "outputId": "bc44c2da-0442-4b6b-ba51-02b29166a3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2018.1.10)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.130)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.6)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.22)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.130)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (1.11.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B5muvr3Hb5Uk",
        "colab_type": "code",
        "outputId": "a01091e4-0998-4824-9cda-95efc2f8b1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "    \n",
        "!python download_glue_data.py --data_dir glue_data --tasks MNLI # select any number of MNLI,SNLI,QNLI,WNLI"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-12 16:23:37--  https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8225 (8.0K) [text/plain]\n",
            "Saving to: ‘download_glue_data.py’\n",
            "\n",
            "\rdownload_glue_data.   0%[                    ]       0  --.-KB/s               \rdownload_glue_data. 100%[===================>]   8.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-12 16:23:37 (102 MB/s) - ‘download_glue_data.py’ saved [8225/8225]\n",
            "\n",
            "Downloading and extracting MNLI...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dcY5BvJw9Jw",
        "colab_type": "code",
        "outputId": "6af4afca-d674-46e3-e019-59267fef970f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -P /content/glue_data/MNLI/ https://github.com/alexisjihyeross/cs287_causality_project/blob/master/neg_test_matched.tsv\n",
        "!wget -P /content/glue_data/MNLI/ https://github.com/alexisjihyeross/cs287_causality_project/blob/master/neg_test_mismatched.tsv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-12 16:23:57--  https://github.com/alexisjihyeross/cs287_causality_project/blob/master/neg_test_matched.tsv\n",
            "Resolving github.com (github.com)... 140.82.118.3, 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/glue_data/MNLI/neg_test_matched.tsv’\n",
            "\n",
            "neg_test_matched.ts     [ <=>                ]  54.72K   295KB/s    in 0.2s    \n",
            "\n",
            "2019-04-12 16:23:58 (295 KB/s) - ‘/content/glue_data/MNLI/neg_test_matched.tsv’ saved [56029]\n",
            "\n",
            "--2019-04-12 16:23:59--  https://github.com/alexisjihyeross/cs287_causality_project/blob/master/neg_test_mismatched.tsv\n",
            "Resolving github.com (github.com)... 140.82.118.3, 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/glue_data/MNLI/neg_test_mismatched.tsv’\n",
            "\n",
            "neg_test_mismatched     [ <=>                ]  54.77K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-04-12 16:24:00 (5.57 MB/s) - ‘/content/glue_data/MNLI/neg_test_mismatched.tsv’ saved [56086]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z7-WM8kZiNYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import collections\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuETB_FsDz0B",
        "colab_type": "code",
        "outputId": "54b361c7-d8e4-48e8-a344-b76eb21b4a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertModel\n",
        "from pytorch_pretrained_bert.modeling import BertPreTrainedModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1L6iR-dMoXLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "InputExample = collections.namedtuple('InputExample', ['guid', 'text_a', 'text_b', 'label'])\n",
        "InputFeatures = collections.namedtuple('InputFeatures', ['input_ids', 'input_mask', 'segment_ids', 'label_id'])\n",
        "\n",
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            print(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "        tokens_b = tokenizer.tokenize(example.text_b) if example.text_b else None\n",
        "\n",
        "        # truncate sequence pairs, longest one first, accounting for [cls] and [sep]\n",
        "        if example.text_b:\n",
        "            while len(tokens_a) + len(tokens_b) > max_seq_length - 3:\n",
        "                max(tokens_a, tokens_b, key=len).pop()\n",
        "        elif len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "                \n",
        "        # segment_ids indicate token in first or second seq, w/ embedding vectors\n",
        "        # learned for them during pre-training, added to position embedding\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        \n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        \n",
        "        input_mask = [1] * len(input_ids) # Only attend to real tokens\n",
        "\n",
        "        seqs = [tokens, input_ids, input_mask, segment_ids]\n",
        "        \n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        for seq in seqs[1:]:\n",
        "            seq += padding\n",
        "            assert len(seq) == max_seq_length\n",
        "\n",
        "        label_map = {label: i for i, label in enumerate(label_list)}\n",
        "        label_id = label_map[example.label]\n",
        "        \n",
        "        if ex_index < 3:\n",
        "            print(\"*** Example ***\")\n",
        "            print(\"guid: %s\" % (example.guid))\n",
        "            for n, d in zip(['tokens', 'input_ids', 'input_mask', 'segment_ids'], [tokens, input_ids, input_mask, segment_ids]):\n",
        "                print(f'{n}: {\" \".join([str(x) for x in d])}')\n",
        "            print(\"label: %s (id = %d)\" % (example.label, label_id))\n",
        "\n",
        "        features.append(InputFeatures(input_ids, input_mask, segment_ids, label_id))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLETTH-9NEAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MnliProcessor:\n",
        "    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "        \n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            text_a = line[8]\n",
        "            text_b = line[9]\n",
        "            label = line[-1]\n",
        "            examples.append(InputExample(guid, text_a, text_b, label))\n",
        "        return examples\n",
        "    \n",
        "    def get_dataloader(self, data_dir, data_file, tokenizer, batch_size=10, max_seq_len=70):\n",
        "        if data_file not in ['dev_mismatched', 'dev_matched', 'test_matched', 'test_mismatched', 'neg_test_matched', 'neg_test_mismatched', 'train']:\n",
        "            raise KeyError(f'Invalid data file {data_file}')\n",
        "            \n",
        "        data = self._read_tsv(os.path.join(data_dir, f\"{data_file}.tsv\"))\n",
        "        examples = self._create_examples(data, data_file)\n",
        "        labels = self.get_labels()\n",
        "        \n",
        "        train_feats = convert_examples_to_features(examples, labels, max_seq_len, tokenizer)\n",
        "        dataset = [torch.tensor(d, dtype=torch.long) for d in zip(*train_feats)]\n",
        "    \n",
        "        return DataLoader(TensorDataset(*dataset), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSye16L9WadI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model w/ pooled output to linear layer \n",
        "    Params:\n",
        "        `config`: a BertConfig instance with the config to build a new model\n",
        "        `num_labels`: number of classes for classifier. Default = 2\n",
        "    Inputs:\n",
        "        `input_ids`: [batch_size, seq_length] of word token indices\n",
        "        `token_type_ids`: optional [batch_size, seq_length] with [0, 1] for sentence [A, B] tokens\n",
        "        `attention_mask`: optional [batch_size, seq_length] with [0, 1] to mask out attention on padding\n",
        "        `labels`: optional [batch_size] of class output [0, ..., num_labels]\n",
        "    Outputs:\n",
        "        if `labels` is not `None`: CrossEntropy loss of output with labels.\n",
        "        if `labels` is `None`: Class logits [batch_size, num_labels]\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, modification=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        \n",
        "        if modification:\n",
        "            pooled_output = modification(pooled_output)\n",
        "        \n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss, pooled_output\n",
        "        else:\n",
        "            return logits, pooled_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-KZTymYSQONS",
        "colab_type": "code",
        "outputId": "d875da58-540a-4fde-f7e9-669cfc0cbdd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "BERT_SIZE = 'base'  # or 'large'\n",
        "BERT_CASED = False\n",
        "DATA_DIR = 'glue_data/MNLI'\n",
        "CACHE_DIR = 'cache'\n",
        "MODEL = f'bert-{BERT_SIZE}-{\"cased\" if BERT_CASED else \"uncased\"}'\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL, do_lower_case=not BERT_CASED)\n",
        "\n",
        "processor = MnliProcessor()\n",
        "\n",
        "num_labels = len(processor.get_labels())\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 931511.40B/s]\n",
            "100%|██████████| 407873900/407873900 [00:15<00:00, 25942253.66B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZsKDZoCSi7A",
        "colab_type": "code",
        "outputId": "ebbd22a2-adfc-46b5-d46f-5a4a5f40f24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataloader = processor.get_dataloader(DATA_DIR, 'train', tokenizer, max_seq_len=70)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing example 0 of 392702\n",
            "*** Example ***\n",
            "guid: train-0\n",
            "tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]\n",
            "input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "label: neutral (id = 2)\n",
            "*** Example ***\n",
            "guid: train-1\n",
            "tokens: [CLS] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the braves decide to call to recall a guy from triple a then a double a guy goes up to replace him and a [SEP] you lose the things to the following level if the people recall . [SEP]\n",
            "input_ids: 101 2017 2113 2076 1996 2161 1998 1045 3984 2012 2012 2115 2504 7910 2017 4558 2068 2000 1996 2279 2504 2065 2065 2027 5630 2000 9131 1996 1996 6687 2136 1996 13980 5630 2000 2655 2000 9131 1037 3124 2013 6420 1037 2059 1037 3313 1037 3124 3632 2039 2000 5672 2032 1998 1037 102 2017 4558 1996 2477 2000 1996 2206 2504 2065 1996 2111 9131 1012 102\n",
            "input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "label: entailment (id = 1)\n",
            "*** Example ***\n",
            "guid: train-2\n",
            "tokens: [CLS] one of our number will carry out your instructions minute ##ly . [SEP] a member of my team will execute your orders with immense precision . [SEP]\n",
            "input_ids: 101 2028 1997 2256 2193 2097 4287 2041 2115 8128 3371 2135 1012 102 1037 2266 1997 2026 2136 2097 15389 2115 4449 2007 14269 11718 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "label: entailment (id = 1)\n",
            "Writing example 10000 of 392702\n",
            "Writing example 20000 of 392702\n",
            "Writing example 30000 of 392702\n",
            "Writing example 40000 of 392702\n",
            "Writing example 50000 of 392702\n",
            "Writing example 60000 of 392702\n",
            "Writing example 70000 of 392702\n",
            "Writing example 80000 of 392702\n",
            "Writing example 90000 of 392702\n",
            "Writing example 100000 of 392702\n",
            "Writing example 110000 of 392702\n",
            "Writing example 120000 of 392702\n",
            "Writing example 130000 of 392702\n",
            "Writing example 140000 of 392702\n",
            "Writing example 150000 of 392702\n",
            "Writing example 160000 of 392702\n",
            "Writing example 170000 of 392702\n",
            "Writing example 180000 of 392702\n",
            "Writing example 190000 of 392702\n",
            "Writing example 200000 of 392702\n",
            "Writing example 210000 of 392702\n",
            "Writing example 220000 of 392702\n",
            "Writing example 230000 of 392702\n",
            "Writing example 240000 of 392702\n",
            "Writing example 250000 of 392702\n",
            "Writing example 260000 of 392702\n",
            "Writing example 270000 of 392702\n",
            "Writing example 280000 of 392702\n",
            "Writing example 290000 of 392702\n",
            "Writing example 300000 of 392702\n",
            "Writing example 310000 of 392702\n",
            "Writing example 320000 of 392702\n",
            "Writing example 330000 of 392702\n",
            "Writing example 340000 of 392702\n",
            "Writing example 350000 of 392702\n",
            "Writing example 360000 of 392702\n",
            "Writing example 370000 of 392702\n",
            "Writing example 380000 of 392702\n",
            "Writing example 390000 of 392702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SsMuTNyVVn1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, lr=5e-5, warmup=0.1, num_epochs=2, device='cuda', finetune=False):\n",
        "    if not finetune:\n",
        "        for param in model.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "    loss_fct = CrossEntropyLoss()\n",
        "    \n",
        "    batch_size = dataloader.batch_size\n",
        "    \n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    params = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = BertAdam(params, lr=lr, warmup=warmup, t_total=len(dataloader))\n",
        "\n",
        "    model.to(device)\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "\n",
        "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTAkwoqSI_Dq",
        "colab_type": "code",
        "outputId": "f15fd02a-e2d6-4b4b-d81a-9c5d1fea878b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train(model, train_dataloader, num_epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 17/39271 [00:02<1:11:26,  9.16it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}